{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bfb3ca7",
   "metadata": {},
   "source": [
    "# Load and Prepera Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ffe92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bb5998",
   "metadata": {},
   "source": [
    "Load dataset, including metadata info on the cavity frequency and length of the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c51eb8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(run, path='db/'):\n",
    "    file = f'{path}AnalyzedDataFFT_Run_{run}_sliced.xlsx'\n",
    "    meta = pd.read_excel(file,sheet_name=0,header=None)\n",
    "    freq = pd.read_excel(file,sheet_name=1)             # frequecies\n",
    "    fft  = pd.read_excel(file,sheet_name=2)             # power\n",
    "    \n",
    "    data = pd.DataFrame({'freq':freq[1]})\n",
    "    \n",
    "    col = 0\n",
    "    for col_name in fft.columns: # load all the subruns\n",
    "        if col > 0:\n",
    "            data[f'fft{col-1}'] = fft[col_name]\n",
    "        col += 1\n",
    "    \n",
    "    #cavity frequency and number of files in each slice\n",
    "    center = meta[1][3]\n",
    "    length = meta[1][8]\n",
    "    \n",
    "    print(f'Dataset loaded: {file}\\nCavity frequency: {center} Hz\\nfft subrun:{len(data.columns)-1}')\n",
    "    \n",
    "    return data,center,length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a48793",
   "metadata": {},
   "source": [
    "Prepare data to be analyzed:\n",
    "- Select only a 200 bins window around the cavity frequency\n",
    "- Rescale data to yottowatt: in general, the average measured power should be known and equal to the noise temperature of the system, so we can rescale the data so that the power at the cavity frequency is $T_{noise} \\cdot k_B \\cdot \\Delta\\nu_{bin}$ $[W]$\n",
    "- Compute weights, i.e. the errors associated to each bin; the error is assumed to be Poissonian, so they are computed as $\\sqrt{y_{bin}}$. An ulterior term $\\frac{1}{\\sqrt{N}}$ is added as the bin values are obtained as the average over $N = 2731 \\cdot length$ runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d253b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(alldata,center,subrun=0,length=500,bin_width=651,nbins=100):\n",
    "    \n",
    "    N = length*2731 #N=1365500 if length=500\n",
    "    \n",
    "    # select window of 2*nbins bins around center\n",
    "    # default is to select 200 bins of 651 Hz\n",
    "    mask = (alldata['freq']>center-bin_width*nbins) & (alldata['freq']<center+bin_width*nbins)\n",
    "    cavdata = alldata[mask].reset_index()\n",
    "    \n",
    "    # scale data to yottowat\n",
    "    minW = np.min(cavdata[f'fft{subrun}'].copy()) # minimum power in the cavity\n",
    "    \n",
    "    ref = minW**(-1) * 3.5*1.38e-23*651/1e-24 #It is possibile to add an extra contribute to make them integers\n",
    "    cavdata[f'fft{subrun}'] = ref * cavdata[f'fft{subrun}']  # y' \n",
    "    \n",
    "    # set weights\n",
    "    weights = cavdata[f'fft{subrun}']/np.sqrt(N)      # -> y'/sqrt(N)\n",
    "    #weights = np.sqrt(ref)*np.sqrt(cavdata[f'fft{subrun}'])/np.sqrt(N)  #-> sqrt(sigma'/N) = ref*sqrt(y/N)\n",
    "    \n",
    "    freq = cavdata['freq']\n",
    "    fft = cavdata[f'fft{subrun}']\n",
    "    \n",
    "    return freq,fft,weights,ref"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
