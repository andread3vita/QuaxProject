{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5bb2f0",
   "metadata": {},
   "source": [
    "# Load and Prepera Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15d5e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65062947",
   "metadata": {},
   "source": [
    "Load dataset, including metadata info on the cavity frequency and length of the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3eb2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(run, path='db/'):\n",
    "    file = f'{path}AnalyzedDataFFT_Run_{run}_sliced.xlsx'\n",
    "    meta = pd.read_excel(file,sheet_name=0,header=None)\n",
    "    freq = pd.read_excel(file,sheet_name=1)             # frequecies\n",
    "    fft  = pd.read_excel(file,sheet_name=2)             # power\n",
    "    \n",
    "    data = pd.DataFrame({'freq':freq[1]})\n",
    "    \n",
    "    col = 0\n",
    "    for col_name in fft.columns: # load all the subruns\n",
    "        if col > 0:\n",
    "            data[f'fft{col-1}'] = fft[col_name]\n",
    "        col += 1\n",
    "    \n",
    "    #cavity frequency and number of files in each slice\n",
    "    center = meta[1][3]\n",
    "    length = meta[1][8]\n",
    "    \n",
    "    print(f'Dataset loaded: {file}\\nCavity frequency: {center} Hz\\nfft subrun:{len(data.columns)-1}')\n",
    "    \n",
    "    return data,center,length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3141c4d",
   "metadata": {},
   "source": [
    "Prepare data to be analyzed:\n",
    "- Select only a 200 bins window around the cavity frequency\n",
    "- Rescale data to yottowatt: in general, the average measured power should be known and equal to the noise temperature of the system, so we can rescale the data so that the power at the cavity frequency is $T_{noise} \\cdot k_B \\cdot \\Delta\\nu_{bin}$ $[W]$\n",
    "- Compute weights, i.e. the errors associated to each bin; the error is assumed to be equal to $y_{bin}$. An ulterior term $\\frac{1}{\\sqrt{N}}$ is added as the bin values are obtained as the average over $N = 2731 \\cdot length$ runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24598b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(alldata, center, subrun=0, length=500, bin_width=651, nbins=100):\n",
    "    \n",
    "    N = length*2731 #N=1365500 if length=500\n",
    "    \n",
    "    # select window of 2*nbins bins around center\n",
    "    # default is to select 200 bins of 651 Hz\n",
    "    mask = (alldata['freq']>center-bin_width*nbins) & (alldata['freq']<center+bin_width*nbins)\n",
    "    cavdata = alldata[mask].reset_index(drop=True)    \n",
    "    \n",
    "    # scale data to yottowat\n",
    "    minW = np.min(cavdata[f'fft{subrun}'].copy()) # minimum power in the cavity\n",
    "    \n",
    "    # In general, the average measured power should be known and equal to the noise temperature of the system.\n",
    "    # So we can rescale the data so that the power at the cavity frequency is T_noise k_b B (W)\n",
    "    ref = minW**(-1) * 3.5*1.38e-23*651/1e-24\n",
    "    cavdata[f'fft{subrun}'] = ref * cavdata[f'fft{subrun}']  # y' \n",
    " \n",
    "    freq = cavdata['freq']\n",
    "    fft = cavdata[f'fft{subrun}']\n",
    "  \n",
    "    # set weights\n",
    "    weights = calc_weights(fft, N)  # -> y'/sqrt(N)\n",
    "    #weights = np.sqrt(ref)*np.sqrt(cavdata[f'fft{subrun}'])/np.sqrt(N)  #-> sqrt(sigma'/N) = ref*sqrt(y/N)\n",
    "    \n",
    "    return freq, fft, weights, ref, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1965db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weights(data, N=1365500):\n",
    "    weights = data/np.sqrt(N) # -> y'/sqrt(N)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eef16b",
   "metadata": {},
   "source": [
    "## Load Multiple Run Simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dc4ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(path):\n",
    "    listFile=[]\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            listFile.append(os.path.join(root, file))\n",
    "    return listFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ecc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multipleLoad(path='db/', bin_width=651, nbins=100):\n",
    "    \n",
    "    # get list of all the files in the directory\n",
    "    file_list = list_files(path)\n",
    "    InfoDataset = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        \n",
    "        # load dataset:\n",
    "        \n",
    "        meta = pd.read_excel(file,sheet_name=0,header=None)\n",
    "        freq = pd.read_excel(file,sheet_name=1)             # frequecies\n",
    "        fft  = pd.read_excel(file,sheet_name=2)             # power\n",
    "    \n",
    "        data = pd.DataFrame({'freq':freq[1]})\n",
    "    \n",
    "        col = 0\n",
    "        for col_name in fft.columns: # load all the subruns\n",
    "            if col > 0:\n",
    "                data[f'fft{col-1}'] = fft[col_name]\n",
    "            col += 1\n",
    "        #cavity frequency and number of files per run\n",
    "        center = meta[1][3]\n",
    "        length = meta[1][8]\n",
    "        \n",
    "        \n",
    "        # preapare dataset:\n",
    "        \n",
    "        # select window of 2*nbins bins around center\n",
    "        # default is to select 200 bins of 651 Hz\n",
    "        N = length*2731 #N=1365500 if length=500\n",
    "        \n",
    "        mask = (data['freq']>center-bin_width*nbins) & (data['freq']<center+bin_width*nbins)\n",
    "        cavdata = data[mask].reset_index(drop=True)\n",
    "        \n",
    "        cavdata[\"fft\"] = cavdata.iloc[:,1:].mean(axis=1)\n",
    "        cavdata=cavdata[[\"freq\",\"fft\"]]\n",
    "        \n",
    "        # scale data to yottowat\n",
    "        minW = np.min(cavdata[\"fft\"].copy()) # minimum power in the cavity\n",
    "        # In general, the average measured power should be known and equal to the noise temperature of the system.\n",
    "        # So we can rescale the data so that the power at the cavity frequency sia T_noise k_b B (W)\n",
    "        ref = minW**(-1) * 3.5*1.38e-23*651/1e-24 \n",
    "        cavdata[\"fft\"] = ref * cavdata[\"fft\"]   #y' \n",
    "        \n",
    "        # set weights\n",
    "        weights = calc_weights(cavdata[\"fft\"], N)  # -> y'/sqrt(N)\n",
    "        # weights = np.sqrt(ref)*np.sqrt(cavdata[f'fft{subrun}'])/np.sqrt(N)  #-> sqrt(sigma'/N) = ref*sqrt(y/N)       \n",
    "        \n",
    "        Info = {\"name\":file, \"length\":length, \"center\":center,\n",
    "                \"cavdata\":cavdata, \"weights\":weights, \"ref\":ref} \n",
    "        InfoDataset.append(Info)\n",
    "            \n",
    "    return(InfoDataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
