{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca70b56",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4562630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import poisson as pois\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nbimporter\n",
    "import prepData as prep\n",
    "import fitFunc as fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa053391",
   "metadata": {},
   "source": [
    "### Likelihood Ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad8bfc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute likelihood ratios of two hypotheses\n",
    "def lh_ratio(y, model_null, model_alt):\n",
    "    # compute log likelihoods\n",
    "    LogLike_null = sum(norm.logpdf(x=y, loc=model_null.best_fit, scale=np.sqrt(y)))\n",
    "    LogLike_alt  = sum(norm.logpdf(x=y, loc=model_alt.best_fit,  scale=np.sqrt(y)))\n",
    "    \n",
    "    #LogLike_null = sum(pois.logpmf(fft.astype(int), model_null.best_fit.astype(int)))\n",
    "    #LogLike_alt  = sum(pois.logpmf(fft.astype(int), model_alt.best_fit.astype(int)))\n",
    "    \n",
    "    # significance of the test\n",
    "    q = -2 * (LogLike_null - LogLike_alt)\n",
    "    \n",
    "    return(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1061a8",
   "metadata": {},
   "source": [
    "### Generate Toy Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78495f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_toydataset(values, n):\n",
    "    toy_dataset = norm.rvs(loc=values, scale=np.sqrt(values), size=(n,len(values)))\n",
    "    \n",
    "    #toy_dataset = pois.rvs(mu=values, size=(n,len(values)))\n",
    "    \n",
    "    return(toy_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb013de",
   "metadata": {},
   "source": [
    "## Significance Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fdf482",
   "metadata": {},
   "source": [
    "First, we load and prepare the dataset, and fit the background function.  \n",
    "Next, we compute the significance of the observed dataset. In order to do so, we fit the signal+background function and compute the likelihood ratio $q_0^{obs}$ between the signal and null hypothesis. Then, we generate n = 10,000 toy dataset from the expected values given by the fit and repeate the analysis for every new dataset. The original $q_0^{obs}$ is compared with the distribution of $q_0$ obtained from the toy datasets, and the p-value is computed. Lastly, the significance is expressed as the number of $\\sigma$s needed to achieve an equivalent p-value in a standard normal deviation $z = \\Phi^{-1} \\left(1 - p \\right)$.  \n",
    "This process is repeted using every possible frequency as $x_0$, the center of the signal function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a7563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_test(run, signal, path='db/', n=1000):\n",
    "    data,center,length = prep.load_dataset(run, path)\n",
    "    freq, fft, weights, ref = prep.prep_data(data,center,length=length)\n",
    "    res_bkg = fits.fit_bkg(freq, fft, weights, center, ref)\n",
    "    \n",
    "    z = np.zeros(len(freq))\n",
    "    for i in range(len(freq)):\n",
    "        z[i] = significance(freq, fft, weights, center, freq.values[i], res_bkg, signal, n)\n",
    "    \n",
    "    return(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "205f0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance(freq, fft, weights, res_bkg, center, ref, x_0, signal, n=1000, draw = False):\n",
    "    res_sig = fits.fit_sig(freq, fft, weights, x_0, res_bkg, signal)\n",
    "    \n",
    "    # compute likelihood ratio of observed data\n",
    "    q0_obs = lh_ratio(fft, res_bkg, res_sig)\n",
    "    \n",
    "    # generate toy dataset and compute likelihood ratio for all of them\n",
    "    toy_fft = gen_toydataset(res_bkg.best_fit, n)\n",
    "    toy_weights = toy_fft/np.sqrt(1365500) # NOT UP TO DATE !!!!!!!!!!!!!!!!\n",
    "    \n",
    "    q0 = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        toy_bkg = fits.fit_bkg(freq, toy_fft[i], toy_weights[i], center, ref)\n",
    "        toy_sig = fits.fit_sig(freq, toy_fft[i], toy_weights[i], x_0, toy_bkg, signal)\n",
    "        q0[i] = lh_ratio(toy_fft[i], toy_bkg, toy_sig)\n",
    "    \n",
    "    # plot significance distribution\n",
    "    if(draw):\n",
    "        plot_significance(q0, q0_obs)\n",
    "        \n",
    "    # compute p-value\n",
    "    p = sum(q0 >= q0_obs)/n\n",
    "    # compute significance\n",
    "    z = norm.ppf(1-p)\n",
    "        \n",
    "    return(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7867105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_significance(q0, q0_obs):\n",
    "    # prepare canvas\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    \n",
    "    # plot q0 distribution\n",
    "    N = len(q0)\n",
    "    binning = int(np.sqrt(N))\n",
    "    n, bins, _ = plt.hist(q0, bins=binning, density = True, \n",
    "                          facecolor='lightblue', edgecolor='black', label='Toy Experiments')\n",
    "    plt.vlines(q0_obs, 0, max(n), colors='blue', linestyles='--', label='Observed Data')\n",
    "    \n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('q0')\n",
    "    plt.ylabel('PDf')\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
