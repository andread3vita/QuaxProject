{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10194d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import factorial\n",
    "from scipy import optimize\n",
    "from matplotlib.pyplot import cm\n",
    "from lmfit import Model\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy.stats import poisson as pois\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a787f91c",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b83edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset including metadata info\n",
    "def load_dataset(run, path='db/'):\n",
    "    file = f'{path}AnalyzedDataFFT_Run_{run}_sliced.xlsx'\n",
    "    meta = pd.read_excel(file,sheet_name=0,header=None)\n",
    "    freq = pd.read_excel(file,sheet_name=1)             # frequecies\n",
    "    fft  = pd.read_excel(file,sheet_name=2)             # power\n",
    "    \n",
    "    data = pd.DataFrame({'freq':freq[1]})\n",
    "    \n",
    "    col = 0\n",
    "    for col_name in fft.columns: # load all the subruns\n",
    "        if col > 0:\n",
    "            data[f'fft{col-1}'] = fft[col_name]\n",
    "        col += 1\n",
    "    \n",
    "    #cavity frequency and number of files in each slice\n",
    "    center = meta[1][3]\n",
    "    length = meta[1][8]\n",
    "    \n",
    "    print(f'Dataset loaded: {file}\\nCavity frequency: {center} Hz\\nfft subrun:{len(data.columns)-1}')\n",
    "    \n",
    "    return data,center,length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41db0f6",
   "metadata": {},
   "source": [
    "## Background and Signal Fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdddc6d",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a8487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(alldata,center,subrun=0,length=500,bin_width=651,nbins=100):\n",
    "    \n",
    "    N = length*2731 #N=1365500 if length=500\n",
    "    \n",
    "    # select window of 2*nbins bins around center\n",
    "    # default is to select 200 bins of 651 Hz\n",
    "    mask = (alldata['freq']>center-bin_width*nbins) & (alldata['freq']<center+bin_width*nbins)\n",
    "    cavdata = alldata[mask].reset_index()\n",
    "    \n",
    "    # scale data to yottowat\n",
    "    minW = np.min(cavdata[f'fft{subrun}'].copy()) # minimum power in the cavity\n",
    "    \n",
    "    # In general, the average measured power should be known and equal to the noise temperature of the system.\n",
    "    # So we can rescale the data so that the power at the cavity frequency sia T_noise k_b B (W)\n",
    "    ref = minW**(-1) * 3.5*1.38e-23*651/1e-24 #It is possibile to add an extra contribute to make them integers\n",
    "    cavdata[f'fft{subrun}'] = ref * cavdata[f'fft{subrun}']   #y' \n",
    "    \n",
    "    # set weights\n",
    "    #weights = cavdata[f'fft{subrun}']/np.sqrt(N)      # -> y'/sqrt(N)\n",
    "    weights = np.sqrt(ref)*np.sqrt(cavdata[f'fft{subrun}'])/np.sqrt(N)  #-> sqrt(sigma'/N)=ref*sqrt(y/N)\n",
    "    \n",
    "    #This function returns freq,fft and weights\n",
    "    freq = cavdata['freq']\n",
    "    fft=cavdata[f'fft{subrun}']\n",
    "    \n",
    "    return(freq, fft, weights,ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54908fb3",
   "metadata": {},
   "source": [
    "### Fit Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ade3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x,x0,s,mu):\n",
    "    return mu * np.exp(-.5*((x-x0)/s)**2)\n",
    "    \n",
    "def maxwell(x,x0,s,mu):\n",
    "    return mu * x**2/s**3 * np.exp(-.5*((x-x0)/s)**2)\n",
    "    \n",
    "def bkg(x,a,b,c,d,e,f):                                                   \n",
    "    return e**2*abs(x-a+1j*b)**2/abs(x-c+1j*d)**2+f*(x-c)\n",
    "    \n",
    "def signal_gauss(x,a,b,c,d,e,f,x0,s,mu):\n",
    "    return bkg(x,a,b,c,d,e,f) + gaussian(x,x0,s,mu)\n",
    "    \n",
    "def signal_maxwell(x,a,b,c,d,e,f,x0,s,mu):\n",
    "    return bkg(x,a,b,c,d,e,f) + maxwell(x,x0,s,mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769aa03f",
   "metadata": {},
   "source": [
    "### Fit Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_bkg(freq, fft, weights, center, ref):\n",
    "    # set fit model\n",
    "    bkg_model = Model(bkg)\n",
    "    ps = bkg_model.make_params(a={'value':center, 'min':center*0.999, 'max':center*1.01},\n",
    "                               b=2e4,\n",
    "                               c={'value':center, 'min':center*0.999, 'max':center*1.01},\n",
    "                               d=2.2e4,\n",
    "                               e=1e-2*np.sqrt(ref),\n",
    "                               f=1e-12*ref)\n",
    "    # execute fit\n",
    "    result = bkg_model.fit(fft,x=freq,params=ps,weights=1/weights)\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16254461",
   "metadata": {},
   "source": [
    "### Fit Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6927e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sig(freq, fft, weights, x_0, res_bkg, signal, mu_init = 1e-8, mu_vary = True):\n",
    "    \n",
    "    # take result of preliminary background fit to fix starting parameters\n",
    "    p = res_bkg.best_values\n",
    "    \n",
    "    # set fit model\n",
    "    sig_model = Model(signal)\n",
    "    ps = sig_model.make_params(a ={'value':p['a'], 'vary':False},\n",
    "                               b ={'value':p['b'], 'vary':False},\n",
    "                               c ={'value':p['c'], 'vary':False},\n",
    "                               d ={'value':p['d'], 'vary':False},\n",
    "                               e ={'value':p['e'], 'vary':False},\n",
    "                               f ={'value':p['f'], 'vary':False},\n",
    "                               mu={'value':mu_init, 'min':0, 'vary':mu_vary},\n",
    "                               x0={'value':x_0, 'vary':False},\n",
    "                               s ={'value':16*651, 'vary':False}) # fixed value to 16 bins\n",
    "\n",
    "    result = sig_model.fit(fft,x=freq,params=ps,weights=1/weights)\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523157e",
   "metadata": {},
   "source": [
    "### Plot Fit Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be29c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit(freq, fft, weights, fit_result):\n",
    "    # prepare canvas\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    gs = GridSpec(2, 2)\n",
    "    ax  = fig.add_subplot(gs[0,:])\n",
    "    ax1 = fig.add_subplot(gs[1,0])\n",
    "    ax2 = fig.add_subplot(gs[1,1])\n",
    "    \n",
    "    # plot data and best fit\n",
    "    ax.plot(freq,fft,'o',label='data')\n",
    "    ax.plot(freq,fit_result.best_fit,color='red',label='fit')\n",
    "    \n",
    "    fmin,fmax = min(freq),max(freq)\n",
    "    ax.set_xlim([fmin,fmax])\n",
    "    ax.legend()\n",
    "    \n",
    "    #residuals w.r.t. freq\n",
    "    fit_result.plot_residuals(ax=ax1)\n",
    "    \n",
    "    \n",
    "    # plot histogrm of residuals (with the fit)\n",
    "    #rangeMax=int(np.max(res_bkg.residual))+1\n",
    "    \n",
    "    ax2.hist(fit_result.residual,bins=30,density=True)#range=(-rangeMax,rangeMax))\n",
    "    \n",
    "    \n",
    "    #fit_res = norm.fit(res_bkg.residual, loc=0, scale=1)\n",
    "    #ax2.plot(np.linspace(-rangeMax,rangeMax,100),norm.pdf(np.linspace(-rangeMax,rangeMax,100),fit_res[0],fit_res[1]),color=\"red\")\n",
    "    #ax2.axvline(fit_res[0], color='black', linestyle='dashed', linewidth=1)\n",
    "    \n",
    "    #summary_text = \"mean: {}\\n std: {}\".format(np.round(fit_res[0],3),np.round(fit_res[1],3))\n",
    "    #ax2.text(0.9, 0.9, summary_text, transform=fig.gca().transAxes, ha='right', va='top')\n",
    "\n",
    "\n",
    "    # plot of residuals vs. freq and error band\n",
    "    fig3,ax3=plt.subplots(1,1,figsize=(18,5))\n",
    "    \n",
    "    ax3.scatter(freq,fit_result.residual*weights,label=\"residuals\")\n",
    "    ax3.plot(freq, weights,label=\"+$\\sigma$\")\n",
    "    ax3.plot(freq,-weights,label=\"-$\\sigma$\")\n",
    "    ax3.set_xlim([fmin,fmax])\n",
    "    ax3.set_title(\"Residuals vs freq\")\n",
    "    ax3.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    return(fit_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62336fbf",
   "metadata": {},
   "source": [
    "## Significance Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6953f9",
   "metadata": {},
   "source": [
    "### Generate Toy Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39af8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_toydataset(values, n):\n",
    "    toy_dataset = pois.rvs(mu=values, size=(n,len(values)))\n",
    "    return(toy_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d7fd1",
   "metadata": {},
   "source": [
    "### Likelihood Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bd2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute likelihood ratios of two hypotheses\n",
    "def lh_ratio(fft, model_null, model_alt):\n",
    "    # compute log likelihoods\n",
    "    LogLike_null = sum(pois.logpmf(fft.astype(int), model_null.best_fit.astype(int)))\n",
    "    LogLike_alt  = sum(pois.logpmf(fft.astype(int), model_alt.best_fit.astype(int)))\n",
    "    \n",
    "    # significance of the test\n",
    "    q = -2 * (LogLike_null - LogLike_alt)\n",
    "    \n",
    "    return(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe25bcc",
   "metadata": {},
   "source": [
    "### Plot Significance Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29686c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_significance(q0, q0_obs):\n",
    "    # prepare canvas\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    \n",
    "    # plot q0 distribution\n",
    "    N = len(q0)\n",
    "    binning = int(np.sqrt(N))\n",
    "    n, bins, _ = plt.hist(q0, bins=binning, density = True, \n",
    "                          facecolor='lightblue', edgecolor='black', label='Toy Experiments')\n",
    "    plt.vlines(q0_obs, 0, max(n), colors='blue', linestyles='--', label='Observed Data')\n",
    "    \n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('q0')\n",
    "    plt.ylabel('PDf')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52df3b",
   "metadata": {},
   "source": [
    "### Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance(freq, fft, weights, x_0, res_bkg, signal, n=1000, draw = False):\n",
    "    res_sig = fit_sig(freq, fft, weights, x_0, res_bkg, signal)\n",
    "    \n",
    "    # compute likelihood ratio of observed data\n",
    "    q0_obs = lh_ratio(fft, res_bkg, res_sig)\n",
    "    \n",
    "    # generate toy dataset and compute likelihood ratio for all of them\n",
    "    toy_fft = gen_toydataset(res_bkg.best_fit, n)\n",
    "    toy_weights = toy_fft/np.sqrt(1365500)\n",
    "    \n",
    "    q0 = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        toy_bkg = fit_bkg(freq, toy_fft[i], toy_weights[i], center, ref)\n",
    "        toy_sig = fit_sig(freq, toy_fft[i], toy_weights[i], x_0, toy_bkg, signal)\n",
    "        q0[i] = lh_ratio(toy_fft[i], toy_bkg, toy_sig)\n",
    "    \n",
    "    # plot significance distribution\n",
    "    if(draw):\n",
    "        plot_significance(q0, q0_obs)\n",
    "        \n",
    "    # compute p-value\n",
    "    p = sum(q0 >= q0_obs)/n\n",
    "    # compute significance\n",
    "    z = norm.ppf(1-p)\n",
    "        \n",
    "    return(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab8fd3d",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_test(run, signal, path='db/', n=1000):\n",
    "    data,center = load_dataset(run, path)\n",
    "    freq, fft, weights, ref = prep_data(data,center)\n",
    "    res_bkg = fit_bkg(freq, fft, weights, center, ref)\n",
    "    \n",
    "    z = np.zeros(len(freq))\n",
    "    for i in range(len(freq)):\n",
    "        z[i] = significance(freq, fft, weights, freq.values[i], res_bkg, signal, n)\n",
    "    \n",
    "    return(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5e344",
   "metadata": {},
   "source": [
    "# FIT run 395"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6eccd8",
   "metadata": {},
   "source": [
    "Runs:\n",
    "- 389\n",
    "- 392\n",
    "- 394\n",
    "- 395\n",
    "- 397\n",
    "- 399\n",
    "- 407\n",
    "- 409\n",
    "- 411\n",
    "- 413\n",
    "- 415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb0ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data,center,length = load_dataset(395)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b5f3b",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a023cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, fft, weights,ref= prep_data(data,center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1789809",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res_bkg = fit_bkg(freq, fft, weights, center, ref)\n",
    "plot_fit(freq, fft, weights, res_bkg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d9e23",
   "metadata": {},
   "source": [
    "## Signal + background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dfad32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res_sig = fit_sig(freq, fft, weights, center, res_bkg, signal_maxwell)\n",
    "plot_fit(freq, fft, weights, res_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d265e4",
   "metadata": {},
   "source": [
    "# SIGNIFICANCE TEST - run 395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b6bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q0_obs = lh_ratio(fft, res_bkg, res_sig)\n",
    "q0_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5697c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = significance(freq, fft, weights, center, res_bkg, signal_maxwell, 100, True)\n",
    "z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
